Question1:
	- Map Input Record signifie le nombre d'enregistrements d'entrée: les données d'entrée sont divisées en plusieurs blocs, et chaque bloc est traité par une tâche Map. Le nombre total d'enregistrements d'entrée pour toutes les tâches Map est ce que l'on appelle "Map Input Records". 
	- Map Output Record signifie le nombre d'enregistrement de sortie: représentent le nombre total de paires clé-valeur générées en sortie par l'ensemble des tâches Map.
		
Question2:
	- Ces paires clé-valeur constituent l'ensemble intermédiaire de données entre les tâches Map et Reduce. Ces données intermédiaires sont partitionnées et triées en fonction de la clé pour faciliter le traitement par les tâches Reduce.
		
Question3:
	- "Reduce Input Groups" se réfère au nombre de groupes de clés distincts présents dans l'ensemble des données intermédiaires.

Question4:
	- hdfs dfs -ls /user/wangziy, est le chemin vers mon répertoire personel
	- commande transfert de fichiers d'un ordinateur local vers un système distant: scp /Users/wangziyihuifei/eclipse-workspace/tp.jar wangziy@152.77.81.30:/home/wangziy
	
Question5:
	- 2023-11-25 23:01:14,286 INFO mapreduce.JobSubmitter: number of splits:5
	- On constate que le nombre de splits est 5
	- 2023-11-25 23:01:12,280 INFO input.FileInputFormat: Total input files to process : 5
	- On constate que le compteur "Total input files" to process: 5 correspond au nombre de "splits": 5, vu que ce compteur représente le nombre total de repertoires d'entrée à traiter par le job MapReduce, et sur le repertoire /data/miserables, on constate qu'il y a 5 fichiers txt en tant que l'entrée. 
	
Question6:
	- Avec combine
		Combine input records=467439
		Combine output records=45717
	- Sans combine
		Combine input records=0
		Combine output records=0
		
	- En comparant ces valeurs, on constate que Combine input records est passé de 0 à 467439 et Combine output records est passé de 0 à 45717.
	- La différence entre Combine input records et Combine output records donne une indication de réduction des données effectué par le combiner.
	- Du coup, le compteur Combine input records et le compteur Combine output records permettent de vérifier que le combiner a fonctionné.
	
Question7:
	- Avec combine
		Total time spent by all reduces in occupied slots (ms)=3539
		Total time spent by all reduce tasks (ms)=3539
		Total vcore-milliseconds taken by all reduce tasks=3539
		Total megabyte-milliseconds taken by all reduce tasks=7078000
		GC time elapsed (ms)=1488
		CPU time spent (ms)=8840
	- Sans combine
		Total time spent by all reduces in occupied slots (ms)=4292
		Total time spent by all reduce tasks (ms)=4292
		Total vcore-milliseconds taken by all reduce tasks=4292
		Total megabyte-milliseconds taken by all reduce tasks=8584000
		GC time elapsed (ms)=1354
		CPU time spent (ms)=9660
		
	- Les compteurs indiqués ci-dessus peuvent nous donner des informations sur le temps d'exécution, permettent d’estimer le gain effectivement apporté par le combiner.
	- En comparant ces valeurs, on peut observer que les valeurs associées à l'utilisation du combiner sont généralement inférieures à celles sans le combiner. Cela suggère que le combiner a contribué à une réduction du temps d'exécution, de l'utilisation CPU, et potentiellement à une utilisation plus efficace des ressources mémoire. 

Question8:
	- Le mot le plus utilisé est "de", qui répète 17085l fois.
	- En utilisant commandes hadoop fs -cat wordcount/part-r-00000 | awk '{print $2}' | sort -nr | head -1 , on trouve le nombre max est "17085" dans output.
	- En utilisant commandes hadoop fs -cat wordcount/part-r-00000 | grep "17085", on trouve la ligne contiens "17085", du coup, le mot est "de".
	
Question9:
	- Trois Reduceurs
		Shuffled Maps =15
		Merged Map outputs=15
	- Seul Reduceur
		Shuffled Maps =5
		Merged Map outputs=5
		
	- En comparant ces valeurs, on constate que les valeurs avec setNumReduceTasks(3), est trois fois la valeur des champs avec un seul réducteur.
	
Question10:
	-rw-r--r--   1 wangziy wangziy          0 2023-11-27 10:48 wordcount/_SUCCESS
	-rw-r--r--   1 wangziy wangziy      78595 2023-11-27 10:48 wordcount/part-r-00000
	-rw-r--r--   1 wangziy wangziy      79306 2023-11-27 10:48 wordcount/part-r-00001
	-rw-r--r--   1 wangziy wangziy      78473 2023-11-27 10:48 wordcount/part-r-00002
	
	- Nous pouvons consater que ce répertoire a un fichier de sortie pour chaque réducteur (3 fichiers). cependant pour le dépôt en 1.4, nous n'avons qu'un seul fichier de sortie. c'est parce que nous n'avons qu'un seul réducteur. on voit donc que le nombre de fichiers en sortie est lié au nombre de réducteurs.
	
Question11:
	- Trois Reduceurs
		Total time spent by all reduces in occupied slots (ms)=8660
		Total time spent by all reduce tasks (ms)=8660
		Total vcore-milliseconds taken by all reduce tasks=8660

	- Seul Reduceur
		Total time spent by all reduces in occupied slots (ms)=2793
		Total time spent by all reduce tasks (ms)=2793
		Total vcore-milliseconds taken by all reduce tasks=2793
	
	- On peut voir que le temps d'exécution total des tâches de réduction est considérablement réduit lorsqu'un seul reducer est utilisé par rapport à l'utilisation de trois reducers. Cela indique une amélioration significative de la performance lorsqu'il y a moins de reducers. Moins de reducers peut conduire à une moindre surcharge de gestion et une meilleure efficacité dans le traitement des données.
	
Question12: 
	- In-Mapper
		Total time spent by all maps in occupied slots (ms)=23042
		Total time spent by all map tasks (ms)=23042
		
	- Sans In-Mapper
		Total time spent by all maps in occupied slots (ms)=25024
		Total time spent by all map tasks (ms)=25024
		
	- On observe que les valeurs associées au temps d'éxecution de la phase de mapping est réduit, cela signifie In-Mapper Combiner améliorer l'efficacité de la phase de mapping.

Question13: 
	- In-Mapper
		Physical memory (bytes) snapshot=3426861056
		Virtual memory (bytes) snapshot=21057044480
		Peak Map Physical memory (bytes)=568418304
		Peak Map Virtual memory (bytes)=2631835648
		
	- Sans In-Mapper
		Physical memory (bytes) snapshot=3436158976
		Virtual memory (bytes) snapshot=21070225408
		Peak Map Physical memory (bytes)=573571072
		Peak Map Virtual memory (bytes)=2637877248
	
	- On observe que l'utilisation de l'in-mapper combiner semble avoir réduit légèrement la mémoire physique maximale et la mémoire virtuelle maximale utilisée par les mappers.
	- On observe que l'utilisation de l'in-mapper combiner semble avoir légèrement augmenté la mémoire physique maximale et la mémoire virtuelle maximale utilisée par les reducers.
	
Question15: 
	- le type sémantique
		La clé intermédiaire dans le processus MapReduce représente le "Country".
		La valeur intermédiaire représente le "Tag" associés à ce pays.
		
	- le type Java
		Intermediate Key: Text (representing the country)
		Intermediate Value: Text (representing tags associated with the country)

Question18:
	- Les tags les plus utilisés en France sont suivant:
		FR	france 70772
		FR	spain 19558
		FR	europe 12340
		FR	barcelona 24928
		FR	paris 48410

Question19:
	- Oui
	- Espace Mémoire Limité: Sur un cluster Hadoop, la mémoire disponible pour chaque tâche (Mapper ou Reducer) est généralement limitée. Si la taille de la structure en mémoire devient trop grande, cela peut conduire à des erreurs d'OutOfMemory.
	- Combiner: Utilisez le combiner pour effectuer une agrégation partielle des données au niveau des mappers avant qu'elles ne soient transférées au reducer. Cela peut réduire la quantité de données à traiter dans le reducer.
	- Limitation du Nombre de Tags: Si la quantité de données est énorme et que le nombre de tags est très grand, il peut être nécessaire de limiter le nombre de tags pris en compte dans votre analyse, en ne considérant par exemple que les tags les plus fréquents.
	
Question20:
	Job1:
		- Mapper Input Key/Value Types : (LongWritable, Text)
		- Mapper Output Key/Value Types : (Text, StringAndInt)
		- Combiner Output Key/Value Types : (Text, StringAndInt) 
		- Reducer Input Key/Value Types : (Text, StringAndInt)
		- Reducer Output Key/Value Types : (Text, StringAndInt)
		
	Job2:
		- Mapper Input Key/Value Types : (Text, StringAndInt)
		- Mapper Output Key/Value Types : (Text, StringAndInt)
		- Reducer Input Key/Value Types : (Text, StringAndInt)
		- Reducer Output Key/Value Types : (Text, Text)
	
	Comparateur: 
		- Trier les tags par nombre d'occurrences décroissant
		- Découper les tags par pays
	
Question22:
	- Le tri des données étant effectué sur le disque dur, cela limite l'utilisation de la mémoire vive, ce qui est crucial pour gérer de grandes quantités de données de manière scalable et efficace
	
Question24:
	- Non, il n'y a aucune garantie d'obtenir exactement le même résultat d'une exécution à l'autre lorsque des balises sont classées ex aequo dans le top-K pour un pays dans Hadoop MapReduce. La nature distribuée et parallèle du traitement Hadoop peut introduire des variations dans l'ordre des résultats entre les exécutions.
	
	
	
	
	
	
	
	
	
	
	
	
		
	